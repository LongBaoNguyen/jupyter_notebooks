{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Putting It All Together\n",
    "### by Long Nguyen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put together some of the functions implemented in the previous notebooks as well as finally implementing gradient descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to copy and paste from your work on previous notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mnist_loader import load_data_wrapper\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = load_data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images):\n",
    "    \"Plot a list of MNIST images.\"\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(images))\n",
    "    for j, ax in enumerate(axes):\n",
    "        ax.matshow(images[j][0].reshape(28,28), cmap = plt.cm.binary)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement $\\sigma(x)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement the derivative of $\\sigma$. (Hint: $\\sigma'(x)=\\sigma(x)(1-\\sigma(x))$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_prime(x):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement the score function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x, W1, W2, B1, B2):\n",
    "    \"\"\"Return the output of the network if ``x`` is input image and\n",
    "    W1, W2, B1 and B2 are the learnable weights. \"\"\"\n",
    "    Z1 = np.dot(W1, x) + B1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(W2, A1) + B2\n",
    "    A2 = sigmoid(Z2)\n",
    "    return A2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(images, W1, W2, B1, B2):\n",
    "    predictions = []\n",
    "    for im in images:\n",
    "        a = f(img[0], W1, W2, B1, B2)\n",
    "        predictions.append(np.argmax(a))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement vectorize_mini_batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_mini_batch(mini_batch, size):\n",
    "    \"\"\"Given a minibatch of (image,lable) tuples of a certain size\n",
    "    return the tuple X,Y where X contains all of the images and Y contains\n",
    "    all of the labels stacked horizontally \"\"\"\n",
    "    mini_batch_x = [mini_batch[k][0] for k in range(0,size)]\n",
    "    mini_batch_y = [mini_batch[k][1] for k in range(0,size)]\n",
    "    X = np.hstack(mini_batch_x)\n",
    "    Y = np.hstack(mini_batch_y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have an $L$-layer neural network. For an $m\\times n$ matrix $A$, let i-th column of A be denoted by $A[i]$. \n",
    "\n",
    "Let $\\cdot$ denote matrix multiplication and $\\odot$ denote element-wise multiplication. \n",
    "\n",
    "These are the four equations of backpropagation. \n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial J}{\\partial Z_L}&=\\frac{1}{m}(A_L-Y)\\odot\\sigma'(Z_L)\\\\\n",
    "\\frac{\\partial J}{\\partial Z_i}&=\\frac{1}{m}W_{i+1}^T\\cdot \\frac{\\partial J}{\\partial Z_{i+1}}\\odot\\sigma'(Z_i)\\\\\n",
    "\\frac{\\partial J}{\\partial W_i}\n",
    "&=\\frac{\\partial J}{\\partial Z_i}\\cdot A_{i-1}^T\\\\\n",
    "\\frac{\\partial J}{\\partial B_i}\n",
    "&=\\displaystyle\\sum_i \\frac{\\partial J}{\\partial Z_i}[i]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SGD(training_data, epochs, mini_batch_size, eta, test_data):\n",
    "    \"\"\"Gradient descent. \n",
    "    Epochs: the number of times the entire training_data is examined.\n",
    "    mini_batch_size: the number of images used to approximate the gradient \n",
    "    each step of gradient descent.\n",
    "    eta: the learning rate or the step size.\n",
    "    test_data: check accuracy of the model against the test_data every epoch.\n",
    "    \"\"\"\n",
    "    n = len(training_data)\n",
    "    n_test = len(test_data)\n",
    "    W1 = np.random.randn(30, 784)\n",
    "    W2 = np.random.randn(10, 30)\n",
    "    B1 = np.random.randn(30, 1)\n",
    "    B2 = np.random.randn(10, 1)\n",
    "    for j in range(epochs):\n",
    "        random.shuffle(training_data)\n",
    "        for k in range(0, n, mini_batch_size):\n",
    "            mini_batch = training_data[k:k+mini_batch_size]\n",
    "            X, Y = vectorize_mini_batch(mini_batch, mini_batch_size)\n",
    "            #feed forward(vectorized)\n",
    "            Z1 = np.dot(W1, X) + B1\n",
    "            A1 = sigmoid(Z1) \n",
    "            Z2 = np.dot(W2, A1) + B2\n",
    "            A2 = sigmoid(Z2)\n",
    "                    \n",
    "            # backpropagate(vectorized)\n",
    "            dZ2 = 1/mini_batch_size*(A2-Y)*sigmoid_prime(Z2)\n",
    "            dW2 = np.dot(dZ2, A1.T)\n",
    "            dB2 = 1/mini_batch_size*np.sum(dZ2, axis=1, keepdims=True)\n",
    "            dZ1 = 1/mini_batch_size*np.dot(W2.T, dZ2)*sigmoid_prime(Z1)\n",
    "            dW1 = np.dot(dZ1, X.T)\n",
    "            dB1 = 1/mini_batch_size*np.sum(dZ1, axis=1, keepdims=True)\n",
    "            # update parameters by making a gradient step\n",
    "            W2 = W2-eta*dW2\n",
    "            W1 = W1-eta*dW1\n",
    "            B2 = B2-eta*dB2\n",
    "            B1 = B1-eta*dB1\n",
    "            \n",
    "            \n",
    "        # after every epoch, check the accuracy of the model    \n",
    "        test_results = [(np.argmax(f(x, W1, W2, B1, B2)), y) for (x, y) in test_data]\n",
    "        num_correct = sum(int(x == y) for (x, y) in test_results)\n",
    "        print(\"Epoch {} : {} / {}\".format(j, num_correct, n_test));\n",
    "    return W1, B1, W2, B2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : 7333 / 10000\n",
      "Epoch 1 : 8562 / 10000\n",
      "Epoch 2 : 8764 / 10000\n",
      "Epoch 3 : 8894 / 10000\n",
      "Epoch 4 : 8991 / 10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-688eed03380d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-eaade5588601>\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(training_data, epochs, mini_batch_size, eta, test_data)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m#feed forward(vectorized)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mZ1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mB1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mA1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mZ2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mB2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "W1, B1, W2, B2 = SGD(training_data, 30, 10, 3, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
