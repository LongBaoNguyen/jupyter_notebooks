{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Putting It All Together\n",
    "### by Long Nguyen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations for making it this far! In this notebook, we put together some of the functions implemented in the previous notebooks as well as finally implementing gradient descent to recognize handwritten digits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to copy and paste from your work on previous notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mnist_loader import load_data_wrapper\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = load_data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images):\n",
    "    \"Plot a list of MNIST images.\"\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(images))\n",
    "    for j, ax in enumerate(axes):\n",
    "        ax.matshow(images[j][0].reshape(28,28), cmap = plt.cm.binary)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement $\\sigma(x)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement the derivative of $\\sigma$. (Hint: $\\sigma'(x)=\\sigma(x)(1-\\sigma(x))$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_prime(x):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement the score function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x, W1, W2, B1, B2):\n",
    "    \"\"\"Return the output of the network if ``x`` is input image and\n",
    "    W1, W2, B1 and B2 are the learnable weights. \"\"\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(images, W1, W2, B1, B2):\n",
    "    predictions = []\n",
    "    for im in images:\n",
    "        a = f(img[0], W1, W2, B1, B2)\n",
    "        predictions.append(np.argmax(a))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement vectorize_mini_batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_mini_batch(mini_batch, size):\n",
    "    \"\"\"Given a minibatch of (image,lable) tuples of a certain size\n",
    "    return the tuple X,Y where X contains all of the images and Y contains\n",
    "    all of the labels stacked horizontally \"\"\"\n",
    "   \n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have an $L$-layer neural network. For an $m\\times n$ matrix $A$, let i-th column of A be denoted by $A[i]$. \n",
    "\n",
    "Let $\\cdot$ denote matrix multiplication and $\\odot$ denote element-wise multiplication. \n",
    "\n",
    "These are the four equations of backpropagation. \n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial J}{\\partial Z_L}&=\\frac{1}{m}(A_L-Y)\\odot\\sigma'(Z_L)\\\\\n",
    "\\frac{\\partial J}{\\partial Z_i}&=\\frac{1}{m}W_{i+1}^T\\cdot \\frac{\\partial J}{\\partial Z_{i+1}}\\odot\\sigma'(Z_i)\\\\\n",
    "\\frac{\\partial J}{\\partial W_i}\n",
    "&=\\frac{\\partial J}{\\partial Z_i}\\cdot A_{i-1}^T\\\\\n",
    "\\frac{\\partial J}{\\partial B_i}\n",
    "&=\\displaystyle\\sum_i \\frac{\\partial J}{\\partial Z_i}[i]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SGD(training_data, epochs, mini_batch_size, eta, test_data):\n",
    "    \"\"\"Gradient descent. \n",
    "    Epochs: the number of times the entire training_data is examined.\n",
    "    mini_batch_size: the number of images used to approximate the gradient \n",
    "    each step of gradient descent.\n",
    "    eta: the learning rate or the step size.\n",
    "    test_data: check accuracy of the model against the test_data every epoch.\n",
    "    \"\"\"\n",
    "    n = len(training_data)\n",
    "    n_test = len(test_data)\n",
    "    \n",
    "    # randomize the learnable parameters\n",
    "    # use np.random.randn(m,n) for appropriate (m,n)\n",
    "    # use 2-layer neural network with 30-dimensional hidden layer\n",
    "    W1 = \n",
    "    W2 = \n",
    "    B1 = \n",
    "    B2 = \n",
    "    \n",
    "    for j in range(epochs):\n",
    "        random.shuffle(training_data)\n",
    "        for k in range(0, n, mini_batch_size):\n",
    "            # mini_batch of size mini_batch_size\n",
    "            mini_batch = \n",
    "            \n",
    "            # create vectorized input X and labels Y\n",
    "            X, Y = \n",
    "            \n",
    "            \n",
    "            #feed forward(vectorized)\n",
    "            Z1 = \n",
    "            A1 =  \n",
    "            Z2 = \n",
    "            A2 = \n",
    "                    \n",
    "            # backpropagate(vectorized) \n",
    "            # use the four equations of backpropagation\n",
    "            dZ2 = \n",
    "            dW2 = \n",
    "            \n",
    "            # for dB1,dB2 use np.sum with the third argument keepdims=True\n",
    "            # so that the dimensions do not collapse.\n",
    "            dB2 = \n",
    "            dZ1 = \n",
    "            dW1 = \n",
    "            dB1 =\n",
    "            # update parameters by making a gradient step\n",
    "            W1 = \n",
    "            W2 = \n",
    "            B1 =\n",
    "            B2 = \n",
    "            \n",
    "            \n",
    "        # after every epoch, check the accuracy of the model    \n",
    "        test_results = [(np.argmax(f(x, W1, W2, B1, B2)), y) for (x, y) in test_data]\n",
    "        num_correct = sum(int(x == y) for (x, y) in test_results)\n",
    "        print(\"Epoch {} : {} / {}\".format(j, num_correct, n_test));\n",
    "    return W1, B1, W2, B2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : 7333 / 10000\n",
      "Epoch 1 : 8562 / 10000\n",
      "Epoch 2 : 8764 / 10000\n",
      "Epoch 3 : 8894 / 10000\n",
      "Epoch 4 : 8991 / 10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-688eed03380d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-eaade5588601>\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(training_data, epochs, mini_batch_size, eta, test_data)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m#feed forward(vectorized)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mZ1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mB1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mA1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mZ2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mB2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "W1, B1, W2, B2 = SGD(training_data, 30, 10, 3, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
