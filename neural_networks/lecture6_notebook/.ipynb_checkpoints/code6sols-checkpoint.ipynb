{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Writing a Python Program that Recognizes Images\n",
    "### by Long Nguyen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put together some of the functions implemented in the previous notebooks as well as finally implementing gradient descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to copy and paste from your work on previous notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist_loader import load_data_wrapper\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = load_data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images):\n",
    "    \"Plot a list of MNIST images.\"\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(images))\n",
    "    for j, ax in enumerate(axes):\n",
    "        ax.matshow(images[j][0].reshape(28,28), cmap = plt.cm.binary)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement $\\sigma(x)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement the derivative of $\\sigma$. (Hint: $\\sigma'(x)=\\sigma(x)(1-\\sigma(x))$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_prime(x):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement the score function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, W1, W2, B1, B2):\n",
    "    \"\"\"Return the output of the network if ``x`` is input image and\n",
    "    W1, W2, B1 and B2 are the learnable weights. \"\"\"\n",
    "    Z1 = np.dot(W1, x) + B1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(W2, A1) + B2\n",
    "    A2 = sigmoid(Z2)\n",
    "    return A2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(images, W1, W2, B1, B2):\n",
    "    predictions = []\n",
    "    for im in images:\n",
    "        a = f(img[0], W1, W2, B1, B2)\n",
    "        predictions.append(np.argmax(a))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement vectorize_mini_batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-016a84558efe>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-016a84558efe>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    for k in range(0,len(mini_batch):\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def vectorize_mini_batch(mini_batch):\n",
    "    \"\"\"Given a minibatch of (image,lable) tuples of a certain size\n",
    "    return the tuple X,Y where X contains all of the images and Y contains\n",
    "    all of the labels stacked horizontally \"\"\"\n",
    "    mini_batch_x = []\n",
    "    mini_batch_y = []\n",
    "    for k in range(0,len(mini_batch):\n",
    "        mini_batch_x.append(mini_batch[k][0])\n",
    "        mini_batch_y.append(mini_batch[k][1])\n",
    "        \n",
    "    X = np.hstack(mini_batch_x)\n",
    "    Y = np.hstack(mini_batch_y)\n",
    "    return X, Y   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have an $L$-layer neural network. For an $m\\times n$ matrix $A$, let i-th column of A be denoted by $A[i]$. \n",
    "\n",
    "Let $\\cdot$ denote matrix multiplication and $\\odot$ denote element-wise multiplication. \n",
    "\n",
    "These are the four equations of backpropagation. \n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial J}{\\partial Z_L}&=\\frac{1}{m}(A_L-Y)\\odot\\sigma'(Z_L)\\\\\n",
    "\\frac{\\partial J}{\\partial Z_i}&=\\frac{1}{m}W_{i+1}^T\\cdot \\frac{\\partial J}{\\partial Z_{i+1}}\\odot\\sigma'(Z_i)\\\\\n",
    "\\frac{\\partial J}{\\partial W_i}\n",
    "&=\\frac{\\partial J}{\\partial Z_i}\\cdot A_{i-1}^T\\\\\n",
    "\\frac{\\partial J}{\\partial B_i}\n",
    "&=\\frac{1}{m}\\displaystyle\\sum_i \\frac{\\partial J}{\\partial Z_i}[i]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(training_data, epochs, mini_batch_size, eta, test_data):\n",
    "    \"\"\"Gradient descent. \n",
    "    Epochs: the number of times the entire training_data is examined.\n",
    "    mini_batch_size: the number of images used to approximate the gradient \n",
    "    each step of gradient descent.\n",
    "    eta: the learning rate or the step size.\n",
    "    test_data: check accuracy of the model against the test_data every epoch.\n",
    "    \"\"\"\n",
    "    n = len(training_data)\n",
    "    n_test = len(test_data)\n",
    "    W1 = np.random.randn(30, 784)\n",
    "    W2 = np.random.randn(10, 30)\n",
    "    B1 = np.random.randn(30, 1)\n",
    "    B2 = np.random.randn(10, 1)\n",
    "    for j in range(epochs):\n",
    "        random.shuffle(training_data)\n",
    "        for k in range(0, n, mini_batch_size):\n",
    "            mini_batch = training_data[k:k+mini_batch_size]\n",
    "            X, Y = vectorize_mini_batch(mini_batch)\n",
    "            #feed forward(vectorized)\n",
    "            Z1 = np.dot(W1, X) + B1\n",
    "            A1 = sigmoid(Z1) \n",
    "            Z2 = np.dot(W2, A1) + B2\n",
    "            A2 = sigmoid(Z2)\n",
    "                    \n",
    "            # backpropagate(vectorized)\n",
    "            dZ2 = 1/mini_batch_size*(A2-Y)*sigmoid_prime(Z2)\n",
    "            dW2 = np.dot(dZ2, A1.T)\n",
    "            dB2 = 1/mini_batch_size*np.sum(dZ2, axis=1, keepdims=True)          \n",
    "            dZ1 = 1/mini_batch_size*np.dot(W2.T, dZ2)*sigmoid_prime(Z1)\n",
    "            dW1 = np.dot(dZ1, X.T)\n",
    "            dB1 = 1/mini_batch_size*np.sum(dZ1, axis=1, keepdims=True)\n",
    "            # update parameters by making a gradient step\n",
    "            W2 = W2-eta*dW2\n",
    "            W1 = W1-eta*dW1\n",
    "            B2 = B2-eta*dB2\n",
    "            B1 = B1-eta*dB1\n",
    "            \n",
    "            \n",
    "        # after every epoch, check the accuracy of the model    \n",
    "        test_results = [(np.argmax(f(x, W1, W2, B1, B2)), y) for (x, y) in test_data]\n",
    "        num_correct = sum(int(x == y) for (x, y) in test_results)\n",
    "        print(\"Epoch {} : {} / {}\".format(j, num_correct, n_test));\n",
    "    return W1, B1, W2, B2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mini_batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-9aed87c654c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-bcfd78f008b4>\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(training_data, epochs, mini_batch_size, eta, test_data)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mmini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0;31m#feed forward(vectorized)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mZ1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mB1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-483d924efa50>\u001b[0m in \u001b[0;36mvectorize_mini_batch\u001b[0;34m(mini_batch)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmini_batch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmini_batch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mmini_batch_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmini_batch_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mini_batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "W1, B1, W2, B2 = SGD(training_data, 30, 10, 3, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
